# -*- coding: utf-8 -*-
"""DA IA2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/126nTjcPbXaAryrCp3AZj1ZcWAl1GPhpD
"""

# Step 0: Install required libraries
!pip install -q earthengine-api ultralytics opencv-python albumentations

# Step 1: Authenticate Earth Engine
import ee
ee.Authenticate()
ee.Initialize(project='daia-476208')

# Step 2: Imports
import os
import random
import numpy as np
from PIL import Image as PILImage
from io import BytesIO
import requests
from ultralytics import YOLO

# Step 3: Define bounding boxes (regions) for each class
regions = {
    "water": ee.Geometry.Rectangle([72.8, 18.9, 73.0, 19.2]),        # Mumbai coast
    "agriculture": ee.Geometry.Rectangle([75.0, 19.8, 75.6, 20.2]),  # Rural Maharashtra
    "urban": ee.Geometry.Rectangle([77.0, 28.4, 77.3, 28.8])         # Delhi urban
}

NUM_SAMPLES = 70  # per class
BASE_DIR = "/content/sat_dataset"

for split in ["train", "val"]:
    for cls in regions:
        os.makedirs(f"{BASE_DIR}/images/{split}/{cls}", exist_ok=True)
        os.makedirs(f"{BASE_DIR}/labels/{split}/{cls}", exist_ok=True)

# Step 4: Download Sentinel-2 RGB patch
def download_patch(lat, lon, size=256):
    point = ee.Geometry.Point([lon, lat])
    collection = (
        ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED")
        .filterBounds(point)
        .filterDate('2024-01-01', '2024-12-31')
        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))
        .sort('CLOUDY_PIXEL_PERCENTAGE')
    )

    image = collection.first()
    if image is None:
        print(f"No image for {lat}, {lon}")
        return None

    image = image.select(['B4', 'B3', 'B2'])  # RGB bands
    try:
        url = image.getThumbURL({
            'region': point.buffer(500).bounds().getInfo()['coordinates'],
            'dimensions': size,
            'min': 0,
            'max': 3000
        })
        r = requests.get(url, timeout=15)
        r.raise_for_status()
        img = PILImage.open(BytesIO(r.content))
        return np.array(img)
    except Exception as e:
        print(f"Failed download at {lat}, {lon}: {e}")
        return None

# Step 5: Generate random points & save dataset
def save_dataset():
    for cls, region in regions.items():
        print(f"\nSampling points for {cls}...")
        # ‚úÖ Correct usage of randomPoints
        pts = ee.FeatureCollection.randomPoints(region, NUM_SAMPLES, seed=42)
        coords = pts.getInfo()['features']

        for i, feat in enumerate(coords):
            lon, lat = feat['geometry']['coordinates']
            img = download_patch(lat, lon)
            if img is None:
                continue

            split = "train" if random.random() < 0.8 else "val"
            img_path = f"{BASE_DIR}/images/{split}/{cls}/{cls}_{i}.png"
            PILImage.fromarray(img).save(img_path)

            # Label file: full patch as one object
            label_path = f"{BASE_DIR}/labels/{split}/{cls}/{cls}_{i}.txt"
            with open(label_path, 'w') as f:
                f.write(f"{list(regions.keys()).index(cls)} 0.5 0.5 1.0 1.0\n")

save_dataset()

# Step 6: Create YOLOv8 dataset YAML
yaml_content = f"""
path: {BASE_DIR}
train: images/train
val: images/val

nc: {len(regions)}
names: {list(regions.keys())}
"""
with open(f"{BASE_DIR}/data.yaml", 'w') as f:
    f.write(yaml_content)

# Step 7: Train YOLOv8 model
model = YOLO("yolov8n.pt")  # small & fast
model.train(data=f"{BASE_DIR}/data.yaml", epochs=10, imgsz=256, batch=8)

# Step 8: Test multiple random validation images
import glob
val_imgs = glob.glob(f"{BASE_DIR}/images/val/*/*.png")

if len(val_imgs) > 0:
    # Select up to 8 random images (or fewer if not enough available)
    sample_imgs = random.sample(val_imgs, min(8, len(val_imgs)))
    print(f"Testing on {len(sample_imgs)} validation images...")

    for img_path in sample_imgs:
        print("Predicting on:", img_path)
        results = model.predict(img_path, imgsz=256, conf=0.25)
        for r in results:
            r.show()  # Displays the result with bounding boxes
else:
    print("No validation images found. Try re-running dataset generation.")

# üñºÔ∏è Upload and run inference on a custom image
from google.colab import files
uploaded = files.upload()  # choose an image from your system

for filename in uploaded.keys():
    print(f"Running detection on: {filename}")
    results = model.predict(source=filename, imgsz=256, conf=0.25)
    results[0].show()  # show prediction
    # Optional: save result image
    results[0].save(filename=f"pred_{filename}")

print("‚úÖ Inference complete. Check the image preview or 'pred_<filename>' in files.")

# üñºÔ∏è Upload and run inference on a custom image
from google.colab import files
uploaded = files.upload()  # choose an image from your system

for filename in uploaded.keys():
    print(f"Running detection on: {filename}")
    results = model.predict(source=filename, imgsz=256, conf=0.25)
    results[0].show()  # show prediction
    # Optional: save result image
    results[0].save(filename=f"pred_{filename}")

print("‚úÖ Inference complete. Check the image preview or 'pred_<filename>' in files.")

# üñºÔ∏è Upload and run inference on a custom image
from google.colab import files
uploaded = files.upload()  # choose an image from your system

for filename in uploaded.keys():
    print(f"Running detection on: {filename}")
    results = model.predict(source=filename, imgsz=256, conf=0.25)
    results[0].show()  # show prediction
    # Optional: save result image
    results[0].save(filename=f"pred_{filename}")

print("‚úÖ Inference complete. Check the image preview or 'pred_<filename>' in files.")

# üñºÔ∏è Upload and run inference on a custom image
from google.colab import files
uploaded = files.upload()  # choose an image from your system

for filename in uploaded.keys():
    print(f"Running detection on: {filename}")
    results = model.predict(source=filename, imgsz=256, conf=0.25)
    results[0].show()  # show prediction
    # Optional: save result image
    results[0].save(filename=f"pred_{filename}")

print("‚úÖ Inference complete. Check the image preview or 'pred_<filename>' in files.")

# üñºÔ∏è Upload and run inference on a custom image
from google.colab import files
uploaded = files.upload()  # choose an image from your system

for filename in uploaded.keys():
    print(f"Running detection on: {filename}")
    results = model.predict(source=filename, imgsz=256, conf=0.25)
    results[0].show()  # show prediction
    # Optional: save result image
    results[0].save(filename=f"pred_{filename}")

print("‚úÖ Inference complete. Check the image preview or 'pred_<filename>' in files.")

